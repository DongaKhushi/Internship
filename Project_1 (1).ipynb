{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc88873-4b99-41cf-8ee3-2b028cda82fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow is installed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import os\n",
    "import cv2\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "print(\"Pillow is installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a902ad-ca54-4ac5-ba3f-07181db077e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"/Users/garvpatel/Downloads/archive (1) 2/train\"\n",
    "test_dir=\"/Users/garvpatel/Downloads/archive (1) 2/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c831c-d540-4684-a5fb-4bb46ce3c7c7",
   "metadata": {},
   "source": [
    "data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a18f2a-936b-4619-b056-9220acad7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size=(48,48)\n",
    "\n",
    "# def get_hash(image_path):\n",
    "#   with open(image_path,\"rb\") as f:\n",
    "#     return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "# hashes=set()\n",
    "\n",
    "# for emotion in os.listdir(train_dir):\n",
    "#   emotion_path=os.path.join(train_dir,emotion)\n",
    "\n",
    "#   for filename in os.listdir(emotion_path):\n",
    "#     img_path=os.path.join(emotion_path,filename)\n",
    "\n",
    "#     try:\n",
    "#       img=cv2.imread(img_path)\n",
    "#       if img is None:\n",
    "#         print(f\"Corrupt image found and removed: {img_path}\")\n",
    "#         os.remove(img_path)\n",
    "#         continue\n",
    "\n",
    "#       img_hash=get_hash(img_path)\n",
    "#       if img_hash in hashes:\n",
    "#         print(f\"Duplicate image found and removed: {img_path}\")\n",
    "#         os.remove(img_path)\n",
    "#         continue\n",
    "\n",
    "#       else:\n",
    "#         hashes.add(img_hash)\n",
    "\n",
    "#       img=Image.open(img_path).convert(\"L\")\n",
    "#       img=img.resize(img_size)\n",
    "#       img.save(img_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#       print(f\"Error processing {img_path}: {e}\")\n",
    "#       os.remove(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23c950-f53a-4df1-8138-2ebf61383c3c",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c93b88-2144-4092-b9ef-d60bcb1db5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2f27b57-72bb-4bab-b1af-04be5b8462f9",
   "metadata": {},
   "source": [
    "resize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67e888c-22a0-44ff-bd84-d03d0bf57d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(48,48),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5b9ac",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a341225",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fdf92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m3,591\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">523,015</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m523,015\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">523,015</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m523,015\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    # Convolutional layers\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    \n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),  # Prevent overfitting\n",
    "    Dense(7, activation='softmax')  # 7 classes for emotions\n",
    "])\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7e30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(\n",
    "    optimizer=SGD(learning_rate=0.01, momentum=0.9),  # Using SGD optimizer with momentum\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526f79d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 114ms/step - accuracy: 0.2382 - loss: 1.8410 - val_accuracy: 0.2471 - val_loss: 1.8078\n",
      "Epoch 2/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.2526 - loss: 1.8041 - val_accuracy: 0.2491 - val_loss: 1.7913\n",
      "Epoch 3/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.2517 - loss: 1.7952 - val_accuracy: 0.2541 - val_loss: 1.7799\n",
      "Epoch 4/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.2503 - loss: 1.7893 - val_accuracy: 0.2534 - val_loss: 1.7661\n",
      "Epoch 5/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.2570 - loss: 1.7812 - val_accuracy: 0.2774 - val_loss: 1.7359\n",
      "Epoch 6/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.2764 - loss: 1.7571 - val_accuracy: 0.3220 - val_loss: 1.6941\n",
      "Epoch 7/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.2935 - loss: 1.7420 - val_accuracy: 0.3312 - val_loss: 1.6831\n",
      "Epoch 8/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.2993 - loss: 1.7275 - val_accuracy: 0.3785 - val_loss: 1.6072\n",
      "Epoch 9/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.3233 - loss: 1.6874 - val_accuracy: 0.4011 - val_loss: 1.5481\n",
      "Epoch 10/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.3457 - loss: 1.6561 - val_accuracy: 0.4035 - val_loss: 1.5279\n",
      "Epoch 11/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.3501 - loss: 1.6399 - val_accuracy: 0.4285 - val_loss: 1.4741\n",
      "Epoch 12/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.3652 - loss: 1.6032 - val_accuracy: 0.4492 - val_loss: 1.4324\n",
      "Epoch 13/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 130ms/step - accuracy: 0.3824 - loss: 1.5719 - val_accuracy: 0.4741 - val_loss: 1.3921\n",
      "Epoch 14/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.4001 - loss: 1.5465 - val_accuracy: 0.4809 - val_loss: 1.3759\n",
      "Epoch 15/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 150ms/step - accuracy: 0.4151 - loss: 1.5103 - val_accuracy: 0.4755 - val_loss: 1.3712\n",
      "Epoch 16/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 132ms/step - accuracy: 0.4230 - loss: 1.4873 - val_accuracy: 0.4734 - val_loss: 1.3602\n",
      "Epoch 17/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.4362 - loss: 1.4598 - val_accuracy: 0.4975 - val_loss: 1.3184\n",
      "Epoch 18/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.4499 - loss: 1.4330 - val_accuracy: 0.5164 - val_loss: 1.2663\n",
      "Epoch 19/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 130ms/step - accuracy: 0.4611 - loss: 1.4049 - val_accuracy: 0.5194 - val_loss: 1.2691\n",
      "Epoch 20/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 127ms/step - accuracy: 0.4637 - loss: 1.3983 - val_accuracy: 0.5098 - val_loss: 1.2577\n",
      "Epoch 21/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.4802 - loss: 1.3627 - val_accuracy: 0.5222 - val_loss: 1.2496\n",
      "Epoch 22/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.4775 - loss: 1.3618 - val_accuracy: 0.5415 - val_loss: 1.1972\n",
      "Epoch 23/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 125ms/step - accuracy: 0.4838 - loss: 1.3534 - val_accuracy: 0.5351 - val_loss: 1.2145\n",
      "Epoch 24/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 133ms/step - accuracy: 0.4909 - loss: 1.3328 - val_accuracy: 0.5426 - val_loss: 1.2068\n",
      "Epoch 25/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 121ms/step - accuracy: 0.4946 - loss: 1.3199 - val_accuracy: 0.5334 - val_loss: 1.2424\n",
      "Epoch 26/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.4977 - loss: 1.3168 - val_accuracy: 0.5506 - val_loss: 1.1705\n",
      "Epoch 27/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.5059 - loss: 1.3052 - val_accuracy: 0.5422 - val_loss: 1.1929\n",
      "Epoch 28/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.5030 - loss: 1.2929 - val_accuracy: 0.5560 - val_loss: 1.1721\n",
      "Epoch 29/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 137ms/step - accuracy: 0.5023 - loss: 1.2948 - val_accuracy: 0.5704 - val_loss: 1.1469\n",
      "Epoch 30/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 153ms/step - accuracy: 0.5078 - loss: 1.2810 - val_accuracy: 0.5709 - val_loss: 1.1427\n",
      "Epoch 31/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.5130 - loss: 1.2758 - val_accuracy: 0.5733 - val_loss: 1.1200\n",
      "Epoch 32/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.5178 - loss: 1.2654 - val_accuracy: 0.5685 - val_loss: 1.1363\n",
      "Epoch 33/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.5237 - loss: 1.2553 - val_accuracy: 0.5727 - val_loss: 1.1244\n",
      "Epoch 34/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.5257 - loss: 1.2495 - val_accuracy: 0.5770 - val_loss: 1.1362\n",
      "Epoch 35/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 121ms/step - accuracy: 0.5282 - loss: 1.2477 - val_accuracy: 0.5762 - val_loss: 1.1209\n",
      "Epoch 36/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5312 - loss: 1.2331 - val_accuracy: 0.5772 - val_loss: 1.1295\n",
      "Epoch 37/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.5310 - loss: 1.2346 - val_accuracy: 0.5741 - val_loss: 1.1291\n",
      "Epoch 38/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.5339 - loss: 1.2286 - val_accuracy: 0.5869 - val_loss: 1.0999\n",
      "Epoch 39/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.5332 - loss: 1.2264 - val_accuracy: 0.5782 - val_loss: 1.1119\n",
      "Epoch 40/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.5408 - loss: 1.2128 - val_accuracy: 0.5847 - val_loss: 1.0962\n",
      "Epoch 41/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5395 - loss: 1.2119 - val_accuracy: 0.5791 - val_loss: 1.1265\n",
      "Epoch 42/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.5405 - loss: 1.2089 - val_accuracy: 0.5862 - val_loss: 1.1042\n",
      "Epoch 43/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.5387 - loss: 1.2059 - val_accuracy: 0.5935 - val_loss: 1.0925\n",
      "Epoch 44/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 128ms/step - accuracy: 0.5513 - loss: 1.2005 - val_accuracy: 0.5775 - val_loss: 1.1006\n",
      "Epoch 45/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.5467 - loss: 1.1875 - val_accuracy: 0.5907 - val_loss: 1.0790\n",
      "Epoch 46/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.5470 - loss: 1.1898 - val_accuracy: 0.5809 - val_loss: 1.1032\n",
      "Epoch 47/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.5489 - loss: 1.1942 - val_accuracy: 0.5913 - val_loss: 1.0746\n",
      "Epoch 48/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 123ms/step - accuracy: 0.5551 - loss: 1.1692 - val_accuracy: 0.5961 - val_loss: 1.0663\n",
      "Epoch 49/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.5584 - loss: 1.1660 - val_accuracy: 0.5972 - val_loss: 1.0683\n",
      "Epoch 50/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5550 - loss: 1.1740 - val_accuracy: 0.5892 - val_loss: 1.0733\n",
      "Epoch 51/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.5616 - loss: 1.1696 - val_accuracy: 0.5984 - val_loss: 1.0730\n",
      "Epoch 52/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.5607 - loss: 1.1736 - val_accuracy: 0.5921 - val_loss: 1.0741\n",
      "Epoch 53/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5565 - loss: 1.1553 - val_accuracy: 0.5950 - val_loss: 1.0748\n",
      "Epoch 54/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 127ms/step - accuracy: 0.5549 - loss: 1.1676 - val_accuracy: 0.6048 - val_loss: 1.0712\n",
      "Epoch 55/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.5626 - loss: 1.1549 - val_accuracy: 0.5906 - val_loss: 1.0760\n",
      "Epoch 56/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.5635 - loss: 1.1645 - val_accuracy: 0.5992 - val_loss: 1.0564\n",
      "Epoch 57/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.5665 - loss: 1.1481 - val_accuracy: 0.5896 - val_loss: 1.0833\n",
      "Epoch 58/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.5642 - loss: 1.1471 - val_accuracy: 0.5967 - val_loss: 1.0711\n",
      "Epoch 59/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 137ms/step - accuracy: 0.5654 - loss: 1.1348 - val_accuracy: 0.6035 - val_loss: 1.0441\n",
      "Epoch 60/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.5663 - loss: 1.1377 - val_accuracy: 0.6074 - val_loss: 1.0552\n",
      "Epoch 61/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.5663 - loss: 1.1384 - val_accuracy: 0.6077 - val_loss: 1.0538\n",
      "Epoch 62/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 156ms/step - accuracy: 0.5704 - loss: 1.1420 - val_accuracy: 0.6062 - val_loss: 1.0586\n",
      "Epoch 63/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 156ms/step - accuracy: 0.5749 - loss: 1.1360 - val_accuracy: 0.6016 - val_loss: 1.0538\n",
      "Epoch 64/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 150ms/step - accuracy: 0.5752 - loss: 1.1189 - val_accuracy: 0.6113 - val_loss: 1.0485\n",
      "Epoch 65/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 137ms/step - accuracy: 0.5724 - loss: 1.1298 - val_accuracy: 0.6134 - val_loss: 1.0353\n",
      "Epoch 66/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 130ms/step - accuracy: 0.5777 - loss: 1.1220 - val_accuracy: 0.6070 - val_loss: 1.0521\n",
      "Epoch 67/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 155ms/step - accuracy: 0.5777 - loss: 1.1234 - val_accuracy: 0.6073 - val_loss: 1.0515\n",
      "Epoch 68/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.5755 - loss: 1.1203 - val_accuracy: 0.6050 - val_loss: 1.0774\n",
      "Epoch 69/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.5715 - loss: 1.1289 - val_accuracy: 0.6074 - val_loss: 1.0390\n",
      "Epoch 70/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.5852 - loss: 1.0920 - val_accuracy: 0.6117 - val_loss: 1.0416\n",
      "Epoch 71/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.5719 - loss: 1.1260 - val_accuracy: 0.6179 - val_loss: 1.0183\n",
      "Epoch 72/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 138ms/step - accuracy: 0.5793 - loss: 1.1100 - val_accuracy: 0.6135 - val_loss: 1.0351\n",
      "Epoch 73/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.5848 - loss: 1.0984 - val_accuracy: 0.6108 - val_loss: 1.0329\n",
      "Epoch 74/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.5816 - loss: 1.1064 - val_accuracy: 0.6098 - val_loss: 1.0423\n",
      "Epoch 75/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.5758 - loss: 1.1079 - val_accuracy: 0.6176 - val_loss: 1.0317\n",
      "Epoch 76/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.5793 - loss: 1.1041 - val_accuracy: 0.6085 - val_loss: 1.0465\n",
      "Epoch 77/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.5827 - loss: 1.1008 - val_accuracy: 0.6138 - val_loss: 1.0357\n",
      "Epoch 78/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.5844 - loss: 1.0988 - val_accuracy: 0.6070 - val_loss: 1.0378\n",
      "Epoch 79/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.5922 - loss: 1.0918 - val_accuracy: 0.6229 - val_loss: 1.0138\n",
      "Epoch 80/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.5905 - loss: 1.0953 - val_accuracy: 0.6215 - val_loss: 1.0075\n",
      "Epoch 81/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.5924 - loss: 1.0946 - val_accuracy: 0.6169 - val_loss: 1.0315\n",
      "Epoch 82/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.5829 - loss: 1.0880 - val_accuracy: 0.6127 - val_loss: 1.0281\n",
      "Epoch 83/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.5899 - loss: 1.0814 - val_accuracy: 0.6186 - val_loss: 1.0249\n",
      "Epoch 84/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 121ms/step - accuracy: 0.5885 - loss: 1.0817 - val_accuracy: 0.6135 - val_loss: 1.0313\n",
      "Epoch 85/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 173ms/step - accuracy: 0.5916 - loss: 1.0838 - val_accuracy: 0.6167 - val_loss: 1.0387\n",
      "Epoch 86/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 139ms/step - accuracy: 0.5954 - loss: 1.0707 - val_accuracy: 0.6138 - val_loss: 1.0418\n",
      "Epoch 87/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 152ms/step - accuracy: 0.5939 - loss: 1.0739 - val_accuracy: 0.6131 - val_loss: 1.0356\n",
      "Epoch 88/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 123ms/step - accuracy: 0.6026 - loss: 1.0694 - val_accuracy: 0.6184 - val_loss: 1.0331\n",
      "Epoch 89/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 140ms/step - accuracy: 0.5940 - loss: 1.0850 - val_accuracy: 0.6193 - val_loss: 1.0427\n",
      "Epoch 90/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 134ms/step - accuracy: 0.5951 - loss: 1.0736 - val_accuracy: 0.6209 - val_loss: 1.0302\n",
      "Epoch 91/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 155ms/step - accuracy: 0.5972 - loss: 1.0680 - val_accuracy: 0.6102 - val_loss: 1.0346\n",
      "Epoch 92/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 151ms/step - accuracy: 0.5937 - loss: 1.0673 - val_accuracy: 0.6183 - val_loss: 1.0160\n",
      "Epoch 93/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.6020 - loss: 1.0587 - val_accuracy: 0.6276 - val_loss: 1.0087\n",
      "Epoch 94/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 131ms/step - accuracy: 0.5934 - loss: 1.0760 - val_accuracy: 0.6225 - val_loss: 1.0268\n",
      "Epoch 95/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 155ms/step - accuracy: 0.5989 - loss: 1.0673 - val_accuracy: 0.6254 - val_loss: 1.0089\n",
      "Epoch 96/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6003 - loss: 1.0676 - val_accuracy: 0.6269 - val_loss: 1.0142\n",
      "Epoch 97/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.5984 - loss: 1.0704 - val_accuracy: 0.6204 - val_loss: 1.0379\n",
      "Epoch 98/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.5970 - loss: 1.0585 - val_accuracy: 0.6140 - val_loss: 1.0175\n",
      "Epoch 99/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 121ms/step - accuracy: 0.5998 - loss: 1.0603 - val_accuracy: 0.6212 - val_loss: 1.0164\n",
      "Epoch 100/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 144ms/step - accuracy: 0.6033 - loss: 1.0458 - val_accuracy: 0.6120 - val_loss: 1.0303\n",
      "Epoch 101/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 133ms/step - accuracy: 0.6013 - loss: 1.0535 - val_accuracy: 0.6233 - val_loss: 1.0113\n",
      "Epoch 102/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 103ms/step - accuracy: 0.5999 - loss: 1.0513 - val_accuracy: 0.6237 - val_loss: 1.0242\n",
      "Epoch 103/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 103ms/step - accuracy: 0.6018 - loss: 1.0597 - val_accuracy: 0.6226 - val_loss: 1.0210\n",
      "Epoch 104/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 102ms/step - accuracy: 0.6050 - loss: 1.0585 - val_accuracy: 0.6230 - val_loss: 0.9986\n",
      "Epoch 105/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 105ms/step - accuracy: 0.6039 - loss: 1.0515 - val_accuracy: 0.6250 - val_loss: 1.0077\n",
      "Epoch 106/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6034 - loss: 1.0462 - val_accuracy: 0.6204 - val_loss: 1.0160\n",
      "Epoch 107/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.5986 - loss: 1.0614 - val_accuracy: 0.6239 - val_loss: 1.0122\n",
      "Epoch 108/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6019 - loss: 1.0582 - val_accuracy: 0.6248 - val_loss: 1.0198\n",
      "Epoch 109/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6045 - loss: 1.0534 - val_accuracy: 0.6266 - val_loss: 1.0130\n",
      "Epoch 110/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.6096 - loss: 1.0466 - val_accuracy: 0.6322 - val_loss: 1.0216\n",
      "Epoch 111/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6056 - loss: 1.0479 - val_accuracy: 0.6282 - val_loss: 1.0099\n",
      "Epoch 112/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.6085 - loss: 1.0398 - val_accuracy: 0.6236 - val_loss: 1.0019\n",
      "Epoch 113/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 141ms/step - accuracy: 0.6086 - loss: 1.0454 - val_accuracy: 0.6307 - val_loss: 1.0003\n",
      "Epoch 114/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 137ms/step - accuracy: 0.6043 - loss: 1.0427 - val_accuracy: 0.6197 - val_loss: 1.0331\n",
      "Epoch 115/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 102ms/step - accuracy: 0.6119 - loss: 1.0313 - val_accuracy: 0.6148 - val_loss: 1.0406\n",
      "Epoch 116/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 103ms/step - accuracy: 0.6096 - loss: 1.0310 - val_accuracy: 0.6311 - val_loss: 1.0146\n",
      "Epoch 117/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 103ms/step - accuracy: 0.6085 - loss: 1.0363 - val_accuracy: 0.6199 - val_loss: 1.0184\n",
      "Epoch 118/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6130 - loss: 1.0270 - val_accuracy: 0.6251 - val_loss: 1.0172\n",
      "Epoch 119/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 103ms/step - accuracy: 0.6161 - loss: 1.0382 - val_accuracy: 0.6215 - val_loss: 1.0200\n",
      "Epoch 120/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 103ms/step - accuracy: 0.6118 - loss: 1.0337 - val_accuracy: 0.6236 - val_loss: 1.0190\n",
      "Epoch 121/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6150 - loss: 1.0230 - val_accuracy: 0.6339 - val_loss: 0.9997\n",
      "Epoch 122/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6133 - loss: 1.0348 - val_accuracy: 0.6330 - val_loss: 0.9974\n",
      "Epoch 123/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6116 - loss: 1.0308 - val_accuracy: 0.6386 - val_loss: 1.0048\n",
      "Epoch 124/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.6094 - loss: 1.0328 - val_accuracy: 0.6342 - val_loss: 1.0169\n",
      "Epoch 125/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6122 - loss: 1.0287 - val_accuracy: 0.6305 - val_loss: 1.0045\n",
      "Epoch 126/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6156 - loss: 1.0127 - val_accuracy: 0.6388 - val_loss: 1.0007\n",
      "Epoch 127/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.6141 - loss: 1.0239 - val_accuracy: 0.6305 - val_loss: 1.0131\n",
      "Epoch 128/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.6197 - loss: 1.0212 - val_accuracy: 0.6268 - val_loss: 1.0243\n",
      "Epoch 129/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.6158 - loss: 1.0225 - val_accuracy: 0.6353 - val_loss: 0.9943\n",
      "Epoch 130/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6236 - loss: 1.0144 - val_accuracy: 0.6328 - val_loss: 1.0071\n",
      "Epoch 131/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.6143 - loss: 1.0281 - val_accuracy: 0.6317 - val_loss: 1.0192\n",
      "Epoch 132/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6171 - loss: 1.0204 - val_accuracy: 0.6286 - val_loss: 1.0009\n",
      "Epoch 133/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6179 - loss: 1.0112 - val_accuracy: 0.6287 - val_loss: 1.0109\n",
      "Epoch 134/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6162 - loss: 1.0162 - val_accuracy: 0.6258 - val_loss: 1.0068\n",
      "Epoch 135/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6218 - loss: 1.0075 - val_accuracy: 0.6275 - val_loss: 1.0078\n",
      "Epoch 136/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.6175 - loss: 1.0201 - val_accuracy: 0.6307 - val_loss: 1.0059\n",
      "Epoch 137/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6208 - loss: 1.0130 - val_accuracy: 0.6317 - val_loss: 1.0129\n",
      "Epoch 138/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6247 - loss: 0.9932 - val_accuracy: 0.6432 - val_loss: 0.9936\n",
      "Epoch 139/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6211 - loss: 0.9998 - val_accuracy: 0.6386 - val_loss: 1.0019\n",
      "Epoch 140/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6215 - loss: 0.9997 - val_accuracy: 0.6382 - val_loss: 0.9900\n",
      "Epoch 141/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 105ms/step - accuracy: 0.6221 - loss: 1.0030 - val_accuracy: 0.6204 - val_loss: 1.0251\n",
      "Epoch 142/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6279 - loss: 0.9895 - val_accuracy: 0.6303 - val_loss: 1.0155\n",
      "Epoch 143/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6197 - loss: 1.0107 - val_accuracy: 0.6357 - val_loss: 0.9898\n",
      "Epoch 144/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 105ms/step - accuracy: 0.6198 - loss: 1.0067 - val_accuracy: 0.6259 - val_loss: 1.0313\n",
      "Epoch 145/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6169 - loss: 1.0156 - val_accuracy: 0.6344 - val_loss: 0.9916\n",
      "Epoch 146/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6258 - loss: 0.9959 - val_accuracy: 0.6333 - val_loss: 1.0156\n",
      "Epoch 147/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6280 - loss: 0.9903 - val_accuracy: 0.6322 - val_loss: 0.9967\n",
      "Epoch 148/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6218 - loss: 0.9957 - val_accuracy: 0.6296 - val_loss: 1.0112\n",
      "Epoch 149/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6275 - loss: 1.0011 - val_accuracy: 0.6413 - val_loss: 0.9822\n",
      "Epoch 150/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6282 - loss: 0.9920 - val_accuracy: 0.6322 - val_loss: 0.9989\n",
      "Epoch 151/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6251 - loss: 0.9951 - val_accuracy: 0.6420 - val_loss: 1.0053\n",
      "Epoch 152/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6240 - loss: 0.9978 - val_accuracy: 0.6382 - val_loss: 1.0107\n",
      "Epoch 153/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6246 - loss: 0.9960 - val_accuracy: 0.6357 - val_loss: 0.9996\n",
      "Epoch 154/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6255 - loss: 0.9900 - val_accuracy: 0.6250 - val_loss: 1.0181\n",
      "Epoch 155/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6264 - loss: 0.9943 - val_accuracy: 0.6268 - val_loss: 1.0180\n",
      "Epoch 156/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6273 - loss: 0.9914 - val_accuracy: 0.6346 - val_loss: 1.0046\n",
      "Epoch 157/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6256 - loss: 0.9860 - val_accuracy: 0.6364 - val_loss: 1.0099\n",
      "Epoch 158/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.6299 - loss: 0.9920 - val_accuracy: 0.6422 - val_loss: 0.9864\n",
      "Epoch 159/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6252 - loss: 0.9995 - val_accuracy: 0.6321 - val_loss: 1.0077\n",
      "Epoch 160/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6277 - loss: 0.9930 - val_accuracy: 0.6402 - val_loss: 0.9952\n",
      "Epoch 161/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6188 - loss: 1.0079 - val_accuracy: 0.6376 - val_loss: 0.9955\n",
      "Epoch 162/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.6217 - loss: 1.0050 - val_accuracy: 0.6333 - val_loss: 0.9990\n",
      "Epoch 163/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.6207 - loss: 1.0019 - val_accuracy: 0.6371 - val_loss: 0.9857\n",
      "Epoch 164/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.6234 - loss: 0.9873 - val_accuracy: 0.6354 - val_loss: 1.0192\n",
      "Epoch 165/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 119ms/step - accuracy: 0.6293 - loss: 0.9928 - val_accuracy: 0.6330 - val_loss: 1.0039\n",
      "Epoch 166/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 122ms/step - accuracy: 0.6333 - loss: 0.9838 - val_accuracy: 0.6296 - val_loss: 1.0141\n",
      "Epoch 167/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.6267 - loss: 0.9986 - val_accuracy: 0.6371 - val_loss: 1.0061\n",
      "Epoch 168/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 148ms/step - accuracy: 0.6336 - loss: 0.9822 - val_accuracy: 0.6404 - val_loss: 0.9921\n",
      "Epoch 169/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 175ms/step - accuracy: 0.6320 - loss: 0.9830 - val_accuracy: 0.6421 - val_loss: 1.0020\n",
      "Epoch 170/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 182ms/step - accuracy: 0.6248 - loss: 0.9956 - val_accuracy: 0.6365 - val_loss: 1.0015\n",
      "Epoch 171/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 124ms/step - accuracy: 0.6295 - loss: 0.9870 - val_accuracy: 0.6325 - val_loss: 0.9920\n",
      "Epoch 172/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 155ms/step - accuracy: 0.6264 - loss: 0.9970 - val_accuracy: 0.6376 - val_loss: 0.9998\n",
      "Epoch 173/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 155ms/step - accuracy: 0.6245 - loss: 0.9845 - val_accuracy: 0.6407 - val_loss: 0.9921\n",
      "Epoch 174/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.6362 - loss: 0.9761 - val_accuracy: 0.6335 - val_loss: 1.0057\n",
      "Epoch 175/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.6346 - loss: 0.9787 - val_accuracy: 0.6346 - val_loss: 1.0077\n",
      "Epoch 176/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.6313 - loss: 0.9882 - val_accuracy: 0.6326 - val_loss: 0.9985\n",
      "Epoch 177/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 114ms/step - accuracy: 0.6288 - loss: 0.9802 - val_accuracy: 0.6312 - val_loss: 0.9893\n",
      "Epoch 178/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.6327 - loss: 0.9851 - val_accuracy: 0.6346 - val_loss: 1.0137\n",
      "Epoch 179/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.6331 - loss: 0.9673 - val_accuracy: 0.6337 - val_loss: 1.0218\n",
      "Epoch 180/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 114ms/step - accuracy: 0.6330 - loss: 0.9755 - val_accuracy: 0.6397 - val_loss: 0.9901\n",
      "Epoch 181/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.6369 - loss: 0.9702 - val_accuracy: 0.6353 - val_loss: 1.0158\n",
      "Epoch 182/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.6337 - loss: 0.9688 - val_accuracy: 0.6342 - val_loss: 1.0187\n",
      "Epoch 183/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.6271 - loss: 0.9793 - val_accuracy: 0.6332 - val_loss: 1.0056\n",
      "Epoch 184/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.6376 - loss: 0.9672 - val_accuracy: 0.6438 - val_loss: 0.9992\n",
      "Epoch 185/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 121ms/step - accuracy: 0.6263 - loss: 0.9849 - val_accuracy: 0.6413 - val_loss: 1.0116\n",
      "Epoch 186/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 126ms/step - accuracy: 0.6343 - loss: 0.9674 - val_accuracy: 0.6402 - val_loss: 0.9818\n",
      "Epoch 187/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 138ms/step - accuracy: 0.6314 - loss: 0.9726 - val_accuracy: 0.6428 - val_loss: 0.9869\n",
      "Epoch 188/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 154ms/step - accuracy: 0.6362 - loss: 0.9649 - val_accuracy: 0.6369 - val_loss: 0.9872\n",
      "Epoch 189/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.6324 - loss: 0.9794 - val_accuracy: 0.6403 - val_loss: 1.0047\n",
      "Epoch 190/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 109ms/step - accuracy: 0.6358 - loss: 0.9708 - val_accuracy: 0.6397 - val_loss: 0.9970\n",
      "Epoch 191/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.6380 - loss: 0.9659 - val_accuracy: 0.6376 - val_loss: 0.9936\n",
      "Epoch 192/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 108ms/step - accuracy: 0.6413 - loss: 0.9630 - val_accuracy: 0.6389 - val_loss: 0.9902\n",
      "Epoch 193/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.6391 - loss: 0.9578 - val_accuracy: 0.6333 - val_loss: 0.9899\n",
      "Epoch 194/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 123ms/step - accuracy: 0.6306 - loss: 0.9767 - val_accuracy: 0.6424 - val_loss: 1.0105\n",
      "Epoch 195/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 120ms/step - accuracy: 0.6382 - loss: 0.9697 - val_accuracy: 0.6406 - val_loss: 0.9919\n",
      "Epoch 196/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 125ms/step - accuracy: 0.6380 - loss: 0.9714 - val_accuracy: 0.6245 - val_loss: 1.0018\n",
      "Epoch 197/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 114ms/step - accuracy: 0.6334 - loss: 0.9720 - val_accuracy: 0.6436 - val_loss: 0.9865\n",
      "Epoch 198/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 133ms/step - accuracy: 0.6387 - loss: 0.9646 - val_accuracy: 0.6335 - val_loss: 1.0129\n",
      "Epoch 199/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6373 - loss: 0.9678 - val_accuracy: 0.6347 - val_loss: 1.0033\n",
      "Epoch 200/200\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6400 - loss: 0.9696 - val_accuracy: 0.6371 - val_loss: 1.0179\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=200,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993e5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6380 - loss: 1.0264\n",
      "Test Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ab77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "model.save('Model2.h5')  # Saves model in .h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f87e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('Model2.h5')\n",
    "\n",
    "# Now, you can use `model.predict()` for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "441cd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing import image # type: ignore\n",
    "\n",
    "# # Load an image for testing\n",
    "# img_path = \"C:/Users/Lenovo/Desktop/Project-1/test/disgust/PrivateTest_3881740.jpg\"\n",
    "# img = image.load_img(img_path, target_size=(48, 48), color_mode=\"grayscale\")\n",
    "# img_array = image.img_to_array(img) / 255.0\n",
    "# img_array = np.expand_dims(img_array, axis=0)  # Make it batch format\n",
    "\n",
    "# # Predict emotion\n",
    "# predictions = model.predict(img_array)\n",
    "# predicted_class = np.argmax(predictions)\n",
    "\n",
    "# # Emotion labels\n",
    "# emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "# print(\"Predicted Emotion:\", emotion_labels[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# Emotion labels (Modify as per your dataset)\n",
    "emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprise\"]\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default webcam\n",
    "\n",
    "# Load face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face ROI\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize to match model input size (48x48)\n",
    "        face = cv2.resize(face, (48, 48))\n",
    "\n",
    "        # Normalize & reshape\n",
    "        face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "        face = np.expand_dims(face, axis=-1)  # Add channel dimension (grayscale)\n",
    "        face = face / 255.0  # Normalize\n",
    "\n",
    "        # Predict emotion\n",
    "        prediction = model.predict(face)\n",
    "        emotion_label = np.argmax(prediction)\n",
    "        emotion_text = emotions[emotion_label]\n",
    "\n",
    "        # Draw a rectangle around face & put emotion label\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, emotion_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow(\"Live Emotion Detection\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3645f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69fc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33694541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba598646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd7307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0e70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665512b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b22384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe6c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bceadfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
